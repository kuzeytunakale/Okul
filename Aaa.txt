import queue
import threading
import json
import sounddevice as sd
from vosk import Model, KaldiRecognizer
import pyautogui

# 1) Parametreler
MODEL_PATH = "model"       # Vosk TÃ¼rkÃ§e model klasÃ¶rÃ¼nÃ¼z
SAMPLE_RATE = 16000        # Modelin desteklediÄŸi Ã¶rnekleme hÄ±zÄ±
BLOCKSIZE = 8000           # YaklaÅŸÄ±k 0.5 saniyelik blok (8000 frame)

# 2) Ses verisini kuyruÄŸa koyan callback
q = queue.Queue()
def audio_callback(indata, frames, time, status):
    if status:
        print("âš ï¸ Ses hatasÄ±:", status)
    q.put(bytes(indata))

# 3) Modeli yÃ¼kleyip recognizerâ€™Ä± oluÅŸtur
model = Model(MODEL_PATH)
rec = KaldiRecognizer(model, SAMPLE_RATE)
# Kelime zamanlamasÄ±na ihtiyacÄ±mÄ±z yok; reset sonrasÄ± temiz algÄ± iÃ§in:
rec.SetWords(False)
rec.SetPartialWords(False)

# 4) TanÄ±ma ve tetikleme dÃ¶ngÃ¼sÃ¼
def recognize_loop():
    while True:
        data = q.get()
        if rec.AcceptWaveform(data):
            # Paket sonundaki kesin sonuÃ§
            result = json.loads(rec.Result())
            text = result.get("text", "")
            if "zÄ±pla" in text:
                pyautogui.press("space")
        else:
            # HenÃ¼z paket bitmeden gelen kÄ±smi sonuÃ§
            partial = json.loads(rec.PartialResult()).get("partial", "")
            if "zÄ±pla" in partial:
                pyautogui.press("space")
                # Tekrar tetiklenmemesi iÃ§in resetleyelim
                rec.Reset()

# 5) Mikrofonu baÅŸlat ve dinlemeye al
stream = sd.RawInputStream(
    samplerate=SAMPLE_RATE,
    blocksize=BLOCKSIZE,
    dtype='int16',
    channels=1,
    callback=audio_callback
)

print("ğŸ™ Dinleniyorâ€¦ â€œzÄ±plaâ€ dediÄŸinizde anÄ±nda tetikleme yapÄ±lacak.")
with stream:
    t = threading.Thread(target=recognize_loop, daemon=True)
    t.start()
    try:
        threading.Event().wait()  # Ctrl+C ile Ã§Ä±kana kadar Ã§alÄ±ÅŸÄ±r
    except KeyboardInterrupt:
        print("\nâš™ï¸ Ã‡Ä±kÄ±lÄ±yorâ€¦")
